{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "\n",
    "1. The girl attacked the boy with the book.\n",
    "the girl used a book to attack a guy, or\n",
    "the girl attacked a guy, the one with a book in his hand.\n",
    "2. We decided to leave on Saturday.\n",
    "we will leave the house on Saturday\n",
    "on saturday we decided to leave the house (ex. next Wednsday).\n",
    "\n",
    "3. I saw a man with a briefcase.\n",
    "this sentence is not ambiguous because I can't see a person using a briefcase. If for example I put a binoculars in place of briefcase it becomes ambiguous, becasue I can see a person that using a binoculars or see a person far away using a binocoulars.\n",
    "4. I saw the planet with a telescope.\n",
    "this sentence is not ambiguous because I can't see a planet using a telescope, only see the planet using a telescope\n",
    "\n",
    "The dependency structures of the two sentences is the same, they are both following this structure:\n",
    "\n",
    "3.\n",
    "```\n",
    "saw: (Root) (VBD)\n",
    "├── I: 1 (PRP)\n",
    "├── man: 1 (NN)\n",
    "│   └── a: 2 (DT)\n",
    "├── with: 1 (IN)\n",
    "│   └── briefcase: 2 (NN)\n",
    "│       └── a: 3 (DT)\n",
    "└── .: 1 (.)\n",
    "```\n",
    "\n",
    "```\n",
    "4.\n",
    "saw: (Root) (VBD)\n",
    "├── I: 1 (PRP)\n",
    "├── planet: 1 (NN)\n",
    "│   └── the: 2 (DT)\n",
    "├── with: 1 (IN)\n",
    "│   └── telescope: 2 (NN)\n",
    "│       └── a: 3 (DT)\n",
    "└── .: 1 (.)\n",
    "```\n",
    "    \n",
    "But the two phrases have a different logical flow:\n",
    "3. \"With a briefcase\" is an attributive complement because it modifies \"a man\" (telling us something about him).\n",
    "4. \"With a telescope\" is an adverbial complement of means because it explains how the action of seeing was performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from prettytable import PrettyTable\n",
    "from nltk.corpus import gutenberg\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend,\n"
     ]
    }
   ],
   "source": [
    "# Load the text of 'Emma' by Jane Austen\n",
    "corpus = gutenberg.raw('austen-emma.txt')\n",
    "print(corpus[0:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Preporcessing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lowercase = corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_stripped = corpus_lowercase.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenized = word_tokenize(corpus_stripped)  # Tokenize the corpus\n",
    "corpus_tokenized[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('--', 3100), (\"''\", 2452), ('``', 1735), ('mr.', 1091), (\"'s\", 928), ('emma', 860), ('could', 836), ('would', 818), ('mrs.', 668), ('miss', 599), ('must', 566), ('harriet', 500), ('much', 484), ('said', 483), ('one', 447), ('weston', 437), ('every', 435), ('thing', 394), ('think', 383), ('elton', 383), ('knightley', 379), ('well', 378), ('little', 359), ('never', 358), ('know', 335), ('might', 325), ('good', 313), ('woodhouse', 310), ('say', 310), ('jane', 301), ('quite', 282), ('time', 275), ('great', 263), ('nothing', 252), ('dear', 241), ('always', 238), ('man', 233), ('fairfax', 233), ('thought', 225), ('soon', 223), ('see', 222), ('may', 221), ('churchill', 220), ('shall', 217), ('without', 214), ('frank', 207), ('first', 205), ('father', 202), ('sure', 201), ('made', 199), ('like', 197), ('indeed', 196), ('ever', 193), ('oh', 193), ('body', 192), ('young', 192), ('two', 178), ('though', 177), ('friend', 175), ('come', 171), ('better', 170), ('day', 160), ('hartfield', 160), ('give', 159), ('upon', 159), ('really', 153), ('way', 152), ('make', 151), ('bates', 147), ('rather', 146), ('long', 144), ('us', 143), ('hope', 142), ('seemed', 141), ('done', 140), ('many', 138), ('away', 137), ('poor', 136), ('wish', 134), ('even', 132), ('woman', 131), ('however', 130), ('go', 130), ('home', 128), ('enough', 128), ('mind', 126), ('highbury', 124), ('yes', 124), ('happy', 123), ('going', 120), ('heard', 120), ('came', 119), ('last', 119), ('take', 119), ('look', 119), ('moment', 118), ('love', 117), ('still', 115), ('pleasure', 114), ('something', 113)]\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords and puntuation marks\n",
    "\n",
    "\n",
    "# first create a list of most used stopwords in the text\n",
    "\n",
    "def highest_freq (d, n, s):\n",
    "\n",
    "  # Filter out stopwords and punctuation marks\n",
    "  filtered_corpus = [word for word in d if word not in s and word not in string.punctuation]\n",
    "      \n",
    "  # Create a frequency distribution for the filtered tokens\n",
    "  freq_dist = FreqDist(filtered_corpus)\n",
    "    \n",
    "  # Get the n most common words and their frequencies\n",
    "  return freq_dist.most_common(n)\n",
    "\n",
    "n=100\n",
    "stopwords_list = stopwords.words('english')  # create list of stopwords which will be used to filter them out\n",
    "top_n_words_sh = highest_freq(corpus_tokenized, n, stopwords_list)\n",
    "print(top_n_words_sh)\n",
    "\n",
    "\n",
    "stopwords_list.extend(['’', \"...\", \"--\", \"''\",\"``\",\"'s\",]) # extend the stopwords list to include the missing puntuation marks\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mr.', 1091), ('emma', 860), ('could', 836), ('would', 818), ('mrs.', 668), ('miss', 599), ('must', 566), ('harriet', 500), ('much', 484), ('said', 483)]\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from corpus\n",
    "filtered_corpus = [word for word in corpus_tokenized if word not in stopwords_list and word not in string.punctuation]\n",
    "\n",
    "word_counts = Counter(filtered_corpus)\n",
    "print(word_counts.most_common(10)) # Print top10 words to check if any stopwords are still missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Build the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('emma', 'jane', 'austen'), ('jane', 'austen', '1816'), ('austen', '1816', 'volume'), ('1816', 'volume', 'chapter'), ('volume', 'chapter', 'emma')]\n"
     ]
    }
   ],
   "source": [
    "# generating trigrams\n",
    "\n",
    "trigrams = list(ngrams(filtered_corpus,3))\n",
    "print(trigrams[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('emma', 'jane', 'austen') 1\n",
      "('jane', 'austen', '1816') 1\n",
      "('austen', '1816', 'volume') 1\n",
      "('1816', 'volume', 'chapter') 1\n",
      "('volume', 'chapter', 'emma') 1\n",
      "('chapter', 'emma', 'woodhouse') 1\n",
      "('emma', 'woodhouse', 'handsome') 1\n",
      "('woodhouse', 'handsome', 'clever') 1\n",
      "('handsome', 'clever', 'rich') 1\n",
      "('clever', 'rich', 'comfortable') 1\n",
      "('rich', 'comfortable', 'home') 1\n",
      "('comfortable', 'home', 'happy') 1\n",
      "('home', 'happy', 'disposition') 1\n",
      "('happy', 'disposition', 'seemed') 1\n",
      "('disposition', 'seemed', 'unite') 1\n",
      "('seemed', 'unite', 'best') 1\n",
      "('unite', 'best', 'blessings') 1\n",
      "('best', 'blessings', 'existence') 2\n",
      "('blessings', 'existence', 'lived') 1\n",
      "('existence', 'lived', 'nearly') 1\n"
     ]
    }
   ],
   "source": [
    "#  Counts of each unique n-gram in the corpus.\n",
    "\n",
    "# Compute the frequency distribution of trigrams\n",
    "tri_counts = Counter(trigrams)\n",
    "\n",
    "# Convert the Counter object to a dictionary for the output\n",
    "tri_freq_dict = dict(tri_counts)\n",
    "\n",
    "# check the dictionary\n",
    "count = 0\n",
    "for key, value in tri_freq_dict.items():\n",
    "    print(key, value)\n",
    "    count += 1\n",
    "    if count == 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate the conditional probability of each word following a given (n-1) word sequence based on the n-grams counts.\n",
    "\n",
    "# generate bigrams and counter object for bigrams\n",
    "bigrams = list(ngrams(filtered_corpus,2))\n",
    "bi_counts = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('emma', 'jane', 'austen'): 0.000014\n",
      "('jane', 'austen', '1816'): 0.000014\n",
      "('austen', '1816', 'volume'): 0.000014\n",
      "('1816', 'volume', 'chapter'): 0.000014\n",
      "('volume', 'chapter', 'emma'): 0.000014\n",
      "('chapter', 'emma', 'woodhouse'): 0.000014\n",
      "('emma', 'woodhouse', 'handsome'): 0.000014\n",
      "('woodhouse', 'handsome', 'clever'): 0.000014\n",
      "('handsome', 'clever', 'rich'): 0.000014\n",
      "('clever', 'rich', 'comfortable'): 0.000014\n"
     ]
    }
   ],
   "source": [
    "# generate MLE esitmation for each dictionary key\n",
    "#  Calculate the total number of trigrams\n",
    "total_trigrams = sum(tri_freq_dict.values())\n",
    "\n",
    "#  Compute MLE for each trigram\n",
    "trigram_mle = {key: value / total_trigrams for key, value in tri_freq_dict.items()}\n",
    "\n",
    "# Step 3: Print first 10 MLE values for verification\n",
    "for key, mle in list(trigram_mle.items())[:10]:\n",
    "    print(f\"{key}: {mle:.6f}\")\n",
    "\n",
    "# probably need to be changed to log values, to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word: austen\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(mle_dict, bi_counts, input_bigram):\n",
    "    \"\"\"\n",
    "    Predicts the most likely next word based on a given (n-1)-gram.\n",
    "    \n",
    "    Parameters:\n",
    "    - mle_dict: Dictionary of trigram probabilities\n",
    "    - bi_counts: Counter object with bigram counts\n",
    "    - input_bigram: A tuple containing (n-1) words (a bigram for trigrams)\n",
    "    \n",
    "    Returns:\n",
    "    - Most probable next word, or a random word if input is unseen\n",
    "    \"\"\"\n",
    "    candidates = {trigram: prob for trigram, prob in mle_dict.items() if trigram[:2] == input_bigram}\n",
    "    \n",
    "    if candidates:\n",
    "        # Return the most probable next word\n",
    "        best_trigram = max(candidates, key=candidates.get)  # Find trigram with highest probability\n",
    "        return best_trigram[2]\n",
    "    \n",
    "    else:\n",
    "        # Handle unseen bigram: Choose a random word from known vocabulary\n",
    "        print(f\"Bigram {input_bigram} not found. Selecting random word.\")\n",
    "        return random.choice(list(bi_counts.keys()))[1]  # Return a random word from a known bigram\n",
    "\n",
    "# test\n",
    "input_bigram = ('emma', 'jane')  # input sequence\n",
    "predicted_word = predict_next_word(trigram_mle, bi_counts, input_bigram)\n",
    "print(f\"Predicted next word: {predicted_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ('emma', 'jane') → Predicted next word: austen\n",
      "Input: ('miss', 'taylor') → Predicted next word: would\n",
      "Input: ('rich', 'comfortable') → Predicted next word: home\n",
      "Input: ('mother', 'died') → Predicted next word: long\n",
      "Input: ('handsome', 'clever') → Predicted next word: rich\n",
      "Input: ('last', 'seven') → Predicted next word: years\n",
      "Bigram ('random', 'test') not found. Selecting random word.\n",
      "Input: ('random', 'test') → Predicted next word: operation\n",
      "Bigram ('deep', 'learning') not found. Selecting random word.\n",
      "Input: ('deep', 'learning') → Predicted next word: conscious\n",
      "Bigram ('test', 'bigrams') not found. Selecting random word.\n",
      "Input: ('test', 'bigrams') → Predicted next word: depreciating\n",
      "Bigram ('artificial', 'intelligence') not found. Selecting random word.\n",
      "Input: ('artificial', 'intelligence') → Predicted next word: near\n"
     ]
    }
   ],
   "source": [
    "#model testing with 10 input sequences from within and outside the corpus. \n",
    "#randomly picking some phrases\n",
    "\n",
    "test_bigrams = [\n",
    "    ('emma', 'jane'), #austin\n",
    "    ('miss', 'taylor'),   #would\n",
    "    ('rich', 'comfortable'),  #home\n",
    "    ('mother', 'died'), #long (ago) \n",
    "    ('handsome', 'clever'), #rich\n",
    "    ('last', 'seven'),  #years\n",
    "    ('random', 'test'), \n",
    "    ('deep', 'learning'),  \n",
    "    ('test', 'bigrams'), \n",
    "    ('artificial', 'intelligence')\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for bigram in test_bigrams:\n",
    "    predicted_word = predict_next_word(trigram_mle, bi_counts, bigram)\n",
    "    results[bigram] = predicted_word\n",
    "    print(f\"Input: {bigram} → Predicted next word: {predicted_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short report: Summarize your findings in a brief report of 1-2 page.\n",
    "#attached pdf on canvas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
